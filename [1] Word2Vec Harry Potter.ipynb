{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando um modelo Word2Vec com livros do Harry Potter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec** é um método para gerar *Word Embeddings* a partir de um corpus de texto, utilizando redes neurais.\n",
    "\n",
    "Desenvolvido por Tomas Mikolov *et al.* (Google) em 2013, é um dos métodos de geração de *word embeddings* mais populares em tarefas de processamento de linguagem natural (PLN) como análise de sentimento, tradução de textos e reconhecimento de entidades nomeadas (NER).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para exercitar, vamos treinar um modelo **Word2Vec** com os livros do *Harry Potter*, escritos por J. K. Rowling. \n",
    "\n",
    "Os livros foram retirados [deste repositório](https://github.com/priyanks179/harry-word2vec/tree/master/harry_txt) e traduzidos para português."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1 - importanto as bibliotecas\n",
    "Vamos primeiro instalar e importar as bibliotecas que utilizaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "import nltk\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o pré-processamento em língua portuguesa, vamos usar o pacote ```pt_core_news_sm```. Instale antes com:\n",
    "    \n",
    "```python -m spacy download pt_core_news_sm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 2 - Pré-processamento do *corpus*\n",
    "Aqui eu traduzi os 7 livros do repositório citado acima e concatenei todos em um único arquivo TXT. Retirei os pontos usados em abreviaturas (ex Sr. e Sra.) e fiz um split por \". \", de forma que cada frase fique em uma única linha.\n",
    "\n",
    "Vamos abrir o arquivo e transformá-lo em um *dataframe*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"data\\harry-potter-pt.txt\", \"r\", encoding='UTF-8')\n",
    "df = pd.DataFrame(file)\n",
    "df.columns = ['lines']\n",
    "df = df.sort_index()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim são os textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter E A pedra do feiticeiro byJ K Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r e a Sra Dursley, do número quatro, Rua dos A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eles foram as últimas pessoas que você esperar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O Sr Dursley era o diretor de uma empresa cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ele era um homem grande e musculoso com quase ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68162</th>\n",
       "      <td>Enquanto Harry olhava para ela, ele abaixou a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68163</th>\n",
       "      <td>Eu sei que ele vai. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68164</th>\n",
       "      <td>A cicatriz não doía a Harry há dezenove anos. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68165</th>\n",
       "      <td>Tudo foi bem. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68166</th>\n",
       "      <td>O fim Página 426 \u001a. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68167 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   lines\n",
       "0       Harry Potter E A pedra do feiticeiro byJ K Ro...\n",
       "1      r e a Sra Dursley, do número quatro, Rua dos A...\n",
       "2      Eles foram as últimas pessoas que você esperar...\n",
       "3       O Sr Dursley era o diretor de uma empresa cha...\n",
       "4      Ele era um homem grande e musculoso com quase ...\n",
       "...                                                  ...\n",
       "68162   Enquanto Harry olhava para ela, ele abaixou a...\n",
       "68163                             Eu sei que ele vai. \\n\n",
       "68164   A cicatriz não doía a Harry há dezenove anos. \\n\n",
       "68165                                   Tudo foi bem. \\n\n",
       "68166                             O fim Página 426 \u001a. \\n\n",
       "\n",
       "[68167 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos primeiro remover os acentos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text):\n",
    "    '''Strip accents out.'''\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "clean2 = lambda x: cleaning1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df.lines.apply(remove_accents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter E A pedra do feiticeiro byJ K Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r e a Sra Dursley, do numero quatro, Rua dos A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eles foram as ultimas pessoas que voce esperar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O Sr Dursley era o diretor de uma empresa cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ele era um homem grande e musculoso com quase ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68162</th>\n",
       "      <td>Enquanto Harry olhava para ela, ele abaixou a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68163</th>\n",
       "      <td>Eu sei que ele vai. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68164</th>\n",
       "      <td>A cicatriz nao doia a Harry ha dezenove anos. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68165</th>\n",
       "      <td>Tudo foi bem. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68166</th>\n",
       "      <td>O fim Pagina 426 \u001a. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68167 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   lines\n",
       "0       Harry Potter E A pedra do feiticeiro byJ K Ro...\n",
       "1      r e a Sra Dursley, do numero quatro, Rua dos A...\n",
       "2      Eles foram as ultimas pessoas que voce esperar...\n",
       "3       O Sr Dursley era o diretor de uma empresa cha...\n",
       "4      Ele era um homem grande e musculoso com quase ...\n",
       "...                                                  ...\n",
       "68162   Enquanto Harry olhava para ela, ele abaixou a...\n",
       "68163                             Eu sei que ele vai. \\n\n",
       "68164   A cicatriz nao doia a Harry ha dezenove anos. \\n\n",
       "68165                                   Tudo foi bem. \\n\n",
       "68166                             O fim Pagina 426 \u001a. \\n\n",
       "\n",
       "[68167 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos limpar, usando expressões regulares, tudo que não é caracter alfanumérico e passar tudo para caixa baixa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['lines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x000002479C1FAE60>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brief_cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos lematizar e retirar as *stopwords*, para diminuir a dimensionalidade, com a biblioteca ```spacy```. Vamos usar ```spacy.pipe()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(doc):\n",
    "    # lematizar e retirar stopwords\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # como Word2Vec usa palavras de contexto para aprender a representação vetorial de uma palavra-alvo,\n",
    "    # se uma frase tiver apenas uma ou duas palavras,\n",
    "    # o benefício para o treinamento é muito pequeno    \n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  harry olhar abaixar o mao distraidamente e tocar o cicatriz raiar testo',\n",
       " None,\n",
       " '  o cicatriz nao doia o harry ha dezenove ano',\n",
       " None,\n",
       " '  o paginar']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[68162:68167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt2 = [str(row.strip()) for row in txt if (row != None and row.strip() != '.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o mao harry levantar despedir',\n",
       " 'ficar murmurar ginny',\n",
       " 'harry olhar abaixar o mao distraidamente e tocar o cicatriz raiar testo',\n",
       " 'o cicatriz nao doia o harry ha dezenove ano',\n",
       " 'o paginar']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2[63263:63268]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos removee os valores faltantes e duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harry potter e o pedrar feiticeiro byj k row...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r e o sr dursley numerar ruir alfeneiro orgulh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ultimar pessoa voce esperar estar envolvido es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o sr dursley o diretor empresar chamar grunn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homem e musculoso quase nenhum pescoco ter bigode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68159</th>\n",
       "      <td>o trem dobrar esquinar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68160</th>\n",
       "      <td>o mao harry levantar despedir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68161</th>\n",
       "      <td>ficar murmurar ginny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68162</th>\n",
       "      <td>harry olhar abaixar o mao distraidamente e t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68164</th>\n",
       "      <td>o cicatriz nao doia o harry ha dezenove ano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62168 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   clean\n",
       "0        harry potter e o pedrar feiticeiro byj k row...\n",
       "1      r e o sr dursley numerar ruir alfeneiro orgulh...\n",
       "2      ultimar pessoa voce esperar estar envolvido es...\n",
       "3        o sr dursley o diretor empresar chamar grunn...\n",
       "4      homem e musculoso quase nenhum pescoco ter bigode\n",
       "...                                                  ...\n",
       "68159                             o trem dobrar esquinar\n",
       "68160                      o mao harry levantar despedir\n",
       "68161                               ficar murmurar ginny\n",
       "68162    harry olhar abaixar o mao distraidamente e t...\n",
       "68164        o cicatriz nao doia o harry ha dezenove ano\n",
       "\n",
       "[62168 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63268"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigramas\n",
    "O pacote ```Gensim Phrases``` detecta automaticamente frases comuns (bigramas) de uma lista de frases.\n",
    "\n",
    "Veja mais em: https://radimrehurek.com/gensim/models/phrases.html\n",
    "\n",
    "Com o método ```Phrases()```, vamos criar frases relevantes a partir da lista de frases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Phraser()``` reduz o consumo de memória de ```phrases``` ao descartar estado do modelo não necessário para a detecção de bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos o corpus com base nos bigramas detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Palavras frequentes\n",
    "Vamos calcular a frequencia das palavras, para verificar a eficácia da lematização, remoção de palavras irrelevantes e adição de bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14595"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'e', 'harry', 'nao', 'dizer', 'voce', 'ron', 'hermione', 'ter', 'olhar']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 3 - Treinamento do modelo\n",
    "\n",
    "Hora de treinar nosso modelo Word2Vec com nossos dados. Primeiro, vamos verificar o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from time import time\n",
    "\n",
    "cores = multiprocessing.cpu_count() # conta o número de núcleos do computador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos parametrizar nosso modelo.\n",
    "\n",
    "- *min_count*: Ignora todas as palavras com frequência absoluta total inferior a esta\n",
    "- *window*: A distância máxima entre a palavra atual e a prevista em uma frase. Por exemplo, palavras da janela à esquerda e palavras da janela à esquerda do nosso alvo\n",
    "- *size*: Dimensionalidade dos vetores\n",
    "- *sample*: O limite para configurar quais palavras de alta frequência são reduzidas aleatoriamente\n",
    "- *alpha*: A taxa de aprendizagem inicial\n",
    "- *min_alpha*: A taxa de aprendizado cairá linearmente para *min_alpha* conforme o treinamento progride\n",
    "- *negative*: Se > 0, a amostragem negativa será usada, o int para negativo especifica quantas \"palavras de ruído\" devem ser eliminadas. Se definido como 0, nenhuma amostra negativa é usada\n",
    "- *workers*: Quantidade de *threads* de trabalho para treinar o modelo (treinamento mais rápido com máquinas multicore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=2,\n",
    "                     size=32,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=10,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construindo o vocabulário e treinando o modelo\n",
    "Parâmetros do treinamento:\n",
    "\n",
    "*total_examples: Contagem de sentenças;\n",
    "*epochs*: Número de iterações (épocas) no corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(sentences, progress_per=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8076257, 19146480)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 4 - Salvando o modelo\n",
    "Vamos salvar o modelo nos formatos *KeyedVectors* e binário, para utilizarmos posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.init_sims(replace=True)  # deixa o modelo mais eficiente, pois não vamos mais treiná-lo futuramente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec-harry-potter.model\")\n",
    "w2v_model.wv.save_word2vec_format('model-harry-potter.bin', binary=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já treinamos nosso modelo, [vamos ver aqui como utilizá-lo](https://github.com/lisaterumi/word2vec-harry-potter-portugues/blob/main/%5B2%5D%20tSNE-Harry-Potter.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
